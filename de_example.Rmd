---
title: "An example of RNA-seq differential expression analysis"
author: "Dario Righelli"
date: "17/04/2018"
output: 
    BiocStyle::html_document:
        code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache=TRUE)
```

# The data

We will use the data from [@peixoto2015data].
The gene-level read counts are available on [Github](https://github.com/drisso/peixoto2015_tutorial).
To be faster, I already put a copy of this repository in our repository.

Briefly, the dataset consists of 5 biological replicates per three conditions: controls, fear-condition (memory formation), and memory retrieval.

We also have access to a list of negative control genes, i.e., genes that are not influenced by the biological effect of interest, and to a list of positive control genes, i.e., genes known to be differentially expressed with respect to the biological effect of interest.

We will use these data to show how to perform a typical differential expression 
workflow, using edgeR and DESeq2.

# Packages needed

```{r}
library(RColorBrewer)
library(EDASeq)
library(DESeq2)
library(RUVSeq)
library(edgeR)
library(NOISeq)
```

# Preliminary fundamental steps

Before starting this analysis the raw data (**FASTQ**) have been already independently mapped to the reference genome (mouse) with the **STAR** software outside R.
Producing, in such a way, one BAM file for each sample.
The mapping process consists in assigning the sequence reads to specific regions of the genome. 
The precision of the mapping step depends on the software used and on the parameters used.
NB It is a time demanding step.

Then, in order to quantify the features (genes), the BAM files have been processed together with a **GTF** file to assign the mapped reads to specific features.
As many reads (for each sample) are assigned to a gene as highly is expressed that gene (in that sample).
This process can be performed in R by aid of **featureCounts** function of **RSubread** package.
The final result of this process is a matrix with the genes on the rows and the samples on the columns.
Each cell c[i,j] of the matrix contains the number of reads assigned to  i-th feature in the j-th sample.

Today, we'll work starting with this matrix (the count matrix).

# Exploratory Data Analysis

After reading the counts and the positive and negative control genes in R, we filter out the non expressed genes.

```{r readFC}
data_dir <- "./peixoto2015_tutorial/Peixoto_Input_for_Additional_file_1/"
fc <- read.table(paste0(data_dir, "Peixoto_CC_FC_RT.txt"), row.names=1, header=TRUE)

negControls <- read.table(paste0(data_dir, "Peixoto_NegativeControls.txt"), sep='\t', header=TRUE, as.is=TRUE)

positive <- read.table(paste0(data_dir, "Peixoto_positive_controls.txt"), as.is=TRUE, sep='\t', header=TRUE)

x <- as.factor(rep(c("CC", "FC", "RT"), each=5))
names(x) <- colnames(fc)

cat("Number of starting features: ", dim(fc)[1], "\n")
```

# Filtering

Some of the quantified features (genes) could be very low expressed (presenting values close to 0).
This can affect our analysis, in particular in the detection of differentially expressed genes.
In order to avoid this bias, we filter out these genes.

The filtering can be made with different approaches:

* classical one: filtering out all those genes with expression lesser than a threshold (5).
* statistical approach: using an hipothesis test to detect only the significative ones
    + The NOISeq package provides three different statistical tests through the *filtered.data* function.
        * CPM: removes those features that have an average expression per condition less than cpm value and a coefficient of variation per condition higher than cv.cutoff (in percentage) in all the conditions.
        * Wilcoxon: performs a Wilcoxon test per condition and feature where in the null hypothesis the median expression is 0 and in the alternative the median is higher than 0.
        * Proportion: performs a proportion test on the counts per condition and feature, where null hypothesis is that the feature relative expression (count proportion) is equal to cpm/10^6 and higher than cpm/10^6 for the alternative.

```{r}

filter <- apply(fc, 1, function(x) length(x[which(x>10)])>5)
filtered <- as.matrix(fc)[filter,]
cpmfiltered <- NOISeq::filtered.data(fc, factor=x, norm=FALSE, method=1, cv.cutoff=100, cpm=1)
wilfiltered <- NOISeq::filtered.data(fc, factor=x, norm=FALSE, method=2, cv.cutoff=100, cpm=1)
propfiltered <- NOISeq::filtered.data(fc, factor=x, norm=FALSE, method=3, cv.cutoff=100, cpm=1)

cat("Classical approach filtered features: ", (dim(fc)[1]-dim(filtered)[1]), "\n")
cat("CPM approach filtered features: ", (dim(fc)[1]-dim(cpmfiltered)[1]), "\n")
cat("Wilcoxon approach filtered features: ", (dim(fc)[1]-dim(wilfiltered)[1]), "\n")
cat("Proportion approach filtered features: ", (dim(fc)[1]-dim(propfiltered)[1]), "\n")

```

We are not interested in which is the best one here, so we choose the classical one.
When you perform a real analysis the best approach is to use the one which is filtering not too much and not too few genes.

Now we store the filtered-in genes also for the negative and positive controls.

```{r}
negCon <- intersect(negControls[,2], rownames(filtered))
FCup <- intersect(positive[positive[,3]=="UP",1], rownames(filtered))
FCdown <- intersect(positive[positive[,3]=="DOWN",1], rownames(filtered))
RTup <- intersect(positive[positive[,4]=="UP",1], rownames(filtered))
RTdown <- intersect(positive[positive[,4]=="DOWN",1], rownames(filtered))

colors <- brewer.pal(9, "Set1")
colLib <- colors[x]
``` 

# Normalization
In order to better compare the differences between the conditions, we need to normalize the data.
Multiple approaches are available for the normalization.
Several packages allow to normalize the data:

* EDASeq package the betweenLaneNormalization function implements:
    + Upper Quartile: a normalization based on the third quartile (75% of distribution) 
    + Median: a normalization based on the median of the distribution.
* there are some others implementing the same normalizations or their owns.

There is no best normalization, it all depends on the dataset and on the final results.
    
By aid of *EDASeq* package, we can also use the *plotRLE* and *plotPCA* functions to explore the normalized data.

## Upper quartile

```{r uq}
uq <- betweenLaneNormalization(filtered, which="upper")

plotRLE(uq, col=colLib, outline=FALSE, las=3, ylab="Relative Log Expression", cex.axis=1, cex.lab=1)
plotPCA(uq, col=colLib, cex=1, cex.axis=1, cex.lab=1)
``` 


From these plots we notice that the data points denoted with "3" and "8" are somewhat different from the rest of the samples.

For now, let's filter out these samples.

```{r filter}
idx <- grep("[3,8]", colnames(fc), invert = TRUE)
filter <- apply(fc[, idx], 1, function(x) length(x[which(x>10)])>5)
filtered <- as.matrix(fc)[filter, idx]

x <- as.factor(rep(c("CC", "FC", "RT"), each=3))
names(x) <- colnames(filtered)
colLib <- colors[x]
```


```{r uq2}
uq <- betweenLaneNormalization(filtered, which="upper")

plotRLE(uq, col=colLib, outline=FALSE, las=3, ylab="Relative Log Expression", cex.axis=1, cex.lab=1)
plotPCA(uq, col=colLib, cex=1, cex.axis=1, cex.lab=1)
``` 


# Differential expression with DESeq2

First, we need to create a `DESeqDataSet` object to store the count matrix and the sample-level information.

```{r deseq2}
dds <- DESeqDataSetFromMatrix(countData = filtered,
                              colData = data.frame(Condition = x, 
                                                   Expt = substring(colnames(filtered), 3)),
                              design = ~ Condition)
dds
colData(dds)
```

To test for the differential expression, we can simply call the wrapper function

```{r deseq2de}
dds <- DESeq(dds)
```

This function runs the following in this order.

```{r, eval=FALSE}
dds <- estimateSizeFactors(dds)
dds <- estimateDispersions(dds)
dds <- nbinomWaldTest(dds)
```

<!-- To understand how the dispersion is estimated by `DESeq2`, we can plot it against the mean. -->

<!-- ```{r disp} -->
<!-- plotDispEsts(dds) -->
<!-- ``` -->

<!-- The genewise estimates of the dispersion are shrunk towards the fitted line.  -->
<!-- Some gene-wise estimates are flagged as outliers and not shrunk towards the fitted value. -->

Let's explore the results.

```{r deseq2res}
res <- results(dds)
res
```

Calling `results` without any arguments will extract the estimated log2 fold-changes and p-values for the last variable in the design formula. If there are more than 2 levels for this variable, `results` will extract the results table for a comparison of the last level over the first level.

A nice feature of the `DESeq2` package is that we can easily summarize these results.

```{r deseq2sum}
summary(res)
```

To perform a different comparison, say FC vs. CC, we need to use the `contrast` argument.

```{r deseq2contrast}
res2 <- results(dds, contrast=c("Condition", "FC", "CC"))
summary(res2)
```

To explore the results, we can use look at the MA-plot and the histogram of the p-values.

```{r}
plotMA(res2, ylim=c(-5, 5))
hist(res2$pvalue)
```

This is a good distribution of the p-values. We expect the majority of the genes to be non-differentially expressed, hence leading to a uniform distribution of the p-value and a small portion of genes to be differentially expressed, leading to p-values close to zero.

Another very useful plot is the volcano plot. 
As far as I know, `DESeq2` does not have an automatic function for that, but it is easy to do it "by hand".

```{r}
plot(res2$log2FoldChange, -log10(res2$pvalue), 
     xlab = "log2FC", ylab = "-log10(p)", pch=20, col="grey")
de <- which(res2$padj <= 0.1)
points(res2[de, "log2FoldChange"],
       -log10(res2[de, "pvalue"]),
       pch=20, col=4)
pos <- which(rownames(res2) %in% c(FCup, FCdown))
points(res2[pos, "log2FoldChange"],
       -log10(res2[pos, "pvalue"]),
       pch=1, col=2)
```

## Using all the samples

What happens if we repeat the analysis with all the original samples?

```{r deseq2all}
x_orig <- as.factor(rep(c("CC", "FC", "RT"), each=5))
names(x_orig) <- colnames(fc)

filter <- apply(fc, 1, function(x) length(x[which(x>10)])>5)
filtered_orig <- as.matrix(fc)[filter,]

dds_all <- DESeqDataSetFromMatrix(countData = filtered_orig,
                              colData = data.frame(Condition = x_orig, 
                                                   Expt = substring(colnames(filtered_orig), 3)),
                              design = ~ Condition)
dds_all <- DESeq(dds_all)

res2_all <- results(dds_all, contrast=c("Condition", "FC", "CC"))
summary(res2_all)
```

```{r}
hist(res2_all$pvalue)
```

This is not a good distribution of the p-values. Usually a symptom that the data are affected by batch effects or other unwanted variation.

```{r}
plot(res2_all$log2FoldChange, -log10(res2_all$pvalue), 
     xlab = "log2FC", ylab = "-log10(p)", pch=20, col="grey")
de <- which(res2_all$padj <= 0.1)
points(res2_all[de, "log2FoldChange"],
       -log10(res2_all[de, "pvalue"]),
       pch=20, col=4)
pos <- which(rownames(res2_all) %in% c(FCup, FCdown))
points(res2_all[pos, "log2FoldChange"],
       -log10(res2_all[pos, "pvalue"]),
       pch=1, col=2)
```

## Accounting for unwanted variation

Sometimes filtering out "bad" samples is not feasible or undesirable. 
In such cases, we can try and capture the unwanted variation and include it in the model. 
This is the approach used in the `RUVSeq` package.

```{r ruvseq}
uq <- betweenLaneNormalization(filtered_orig, which="upper")

ruv <- RUVg(uq, cIdx = negCon, k = 5)
plotRLE(ruv$normalizedCounts, col = colors[x_orig], outline=FALSE)
plotPCA(ruv$normalizedCounts, col=colors[x_orig], cex=1, cex.axis=1, cex.lab=1)
```

Now that we checked that these factors account for the unwanted variation, we can include them in the model.

```{r deseq2ruv}
dds_ruv <- DESeqDataSetFromMatrix(countData = filtered_orig,
                              colData = data.frame(Condition = x_orig, 
                                                   Expt = substring(colnames(filtered_orig), 3),
                                                   ruv$W),
                              design = ~ Condition + W_1 + W_2 + W_3 + W_4 + W_5)
dds_ruv <- DESeq(dds_ruv)

res2_ruv <- results(dds_ruv, contrast=c("Condition", "FC", "CC"))
summary(res2_ruv)
```

```{r}
hist(res2_ruv$pvalue)
```

This is a better distribution of the p-values. 
Demonstrating that we have been able to remove the batch effects/unwanted variations.

```{r}
plot(res2_ruv$log2FoldChange, -log10(res2_ruv$pvalue), 
     xlab = "log2FC", ylab = "-log10(p)", pch=20, col="grey")
de <- which(res2_ruv$padj <= 0.1)
points(res2_ruv[de, "log2FoldChange"],
       -log10(res2_ruv[de, "pvalue"]),
       pch=20, col=4)
pos <- which(rownames(res2_ruv) %in% c(FCup, FCdown))
points(res2_ruv[pos, "log2FoldChange"],
       -log10(res2_ruv[pos, "pvalue"]),
       pch=1, col=2)
```

# Differential expression with edgeR

Similarly to `DESeq2`, `edgeR` works on a dedicated object, called `DGEList`, that we need to create from our matrix.

```{r edger}
y <- DGEList(counts = filtered_orig, group = x_orig)
```

The steps of a typical analysis in `edgeR` are very similar to those of `DESeq2`: calculate the normalization factors, estimate the dispersion parameters, and test for differential expression.

```{r edger2}
y <- calcNormFactors(y)
design <- model.matrix(~x_orig + ruv$W)
y <- estimateDisp(y, design)
```

<!-- `estimateDisp` in this case consist of three steps: it first estimates a common dispersion parameter, then a "trend" capturing the relation between dispersion and mean and finally a "tagwise" dispersion parameter shrinked towards the common trend. -->

<!-- In order to understand how this work, we can plot the mean-variance plot. -->

<!-- ```{r meanvar} -->
<!-- meanVarPlot <- plotMeanVar(y,  -->
<!--                            show.raw.vars=TRUE,  -->
<!--                            show.tagwise.vars=TRUE, -->
<!--                            show.binned.common.disp.vars=FALSE, -->
<!--                            show.ave.raw.vars=FALSE,  -->
<!--                            NBline = TRUE , nbins = 100, -->
<!--                            pch = 16,  -->
<!--                            xlab ="Mean Expression (Log10 Scale)",  -->
<!--                            ylab = "Variance (Log10 Scale)" ,  -->
<!--                            main = "Mean-Variance Plot" ) -->
<!-- ``` -->

To test for differential expression, we first fit a generalized linear model (GLM) and then test using the likelihood ratio test.

```{r edger3}

fit <- glmFit(y, design)
lrt <- glmLRT(fit, coef=2)
topTags(lrt)
top <- topTags(lrt, n = Inf)$table

hist(top$PValue)

plot(top$logFC, -log10(top$PValue),
     xlab = "log2FC", ylab = "-log10(p)", pch=20, col="grey")

de <- which(top$FDR <= 0.1)
points(top[de, "logFC"],
       -log10(top[de, "PValue"]),
       pch=20, col=4)
pos <- which(rownames(top) %in% c(FCup, FCdown))
points(top[pos, "logFC"],
       -log10(top[pos, "PValue"]),
       pch=1, col=2)

```

We can test contrasts in `edgeR` in the following way. Imagine we want to test the difference between FC and RT.

```{r contrasts_edger}

colnames(design) <- c("Intercept", "FC", "RT", 
                      "W1", "W2", "W3", "W4", "W5")
cont <- makeContrasts(FC - RT, levels = colnames(design))
cont
lrt <- glmLRT(fit, contrast = cont)
topTags(lrt)
top2 <- topTags(lrt, n = Inf)$table
hist(top$PValue)

```


# A common list of genes

At this point we could want to compare the `edgeR` and the `DESeq2` results in order to obtain a consensul list.

```{r}

source("R/venn2.R")

sign.edger <- top[de,]
res2_ruv.nna <- res2_ruv[!is.na(res2_ruv$padj ),]
sign.des <- res2_ruv.nna[res2_ruv.nna$padj < 0.05,]
int.genes <- Venn2de(x=rownames(sign.edger), y=rownames(as.data.frame(sign.des)), label1="edgeR", label2="RUV_Deseq")

print(head(int.genes))

```

# Functional analysis

A list of genes can be used to obtain a first biological insight by looking at some known annotation databases available online.
By using the **gprofiler** package we can query some of these databases and looking at the cellular mechanisms mostly affected by the obtained gene list.

```{r}
library(gProfileR)

go <- gprofiler(query=int.genes, organism="mmusculus", src_filter="GO")

kegg <- gprofiler(query=int.genes, organism="mmusculus", src_filter="KEGG")

print(head(go))
print(head(kegg))
```

# Session Info
```{r}
sessionInfo()
```


